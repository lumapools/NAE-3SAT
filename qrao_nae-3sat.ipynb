{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import *\n",
    "from qiskit.circuit.library import *\n",
    "from qiskit.providers.aer import AerSimulator\n",
    "method = \"matrix_product_state\"\n",
    "device = \"CPU\"\n",
    "backend = AerSimulator(method=method, device=device)\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qrao import QuantumRandomAccessEncoding, QuantumRandomAccessOptimizer, MagicRounding\n",
    "from qiskit.utils import QuantumInstance\n",
    "import networkx as nx\n",
    "from qiskit_optimization.applications import Maxcut\n",
    "from qiskit.circuit.library import EfficientSU2\n",
    "from qiskit_aer.primitives import Estimator\n",
    "from qiskit.algorithms.minimum_eigensolvers import VQE\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Input CNF\n",
    "A 3SAT CNF is of the form $(x_1 \\lor x_2 \\lor x_3) \\land (\\neg x_2 \\lor x_3 \\lor x_4)$ for example\n",
    "\n",
    "In this notebook, we will assume that the cnf variables ($x_1, x_2, ...$) are given as integers (starting from 0) instead of strings, i.e.\n",
    "$x_1 \\mapsto 0$, $x_2 \\mapsto 1$, etc... This is not very intuitive but it makes parsing easier. We might change it later.\n",
    "\n",
    "- $\\neg$ operator: The negation is denoted by an `n` in front of a particular variable $\\implies$ Ex: $\\neg x_2 \\mapsto$ `n3`\n",
    "- $\\lor$ operator: The $\\lor$ operator is denoted by a space between operands $\\implies$ Ex: $x_1 \\lor \\neg x_2 \\lor x_3 \\mapsto$ `0 n1 2` \n",
    "- $\\land$ operator: The $\\land$ operator is denoted by a comma (`,`) between clauses $\\implies$ Ex: $(x_1 \\lor \\neg x_2 \\lor x_3) \\land (\\neg x_1 \\lor \\neg x_2 \\lor \\neg x_3) \\mapsto$ `0 n1 2,n0 n1 n2`\n",
    "\n",
    "Therefore, for example, given the following CNF:\n",
    "\n",
    "$(x_1 \\lor x_2 \\lor \\neg x_3) \\land (x_3 \\lor \\neg x_1 \\lor \\neg x_6) \\land (\\neg x_2 \\lor x_4 \\lor x_5) \\land (\\neg x_4 \\lor \\neg x_5 \\lor x_6)$\n",
    "\n",
    "the input CNF to this program will be formulated as\n",
    "\n",
    "`0 1 n2,2 n0 n5,n1 3 4,n3 n4 5` (as a string)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the Input CNF\n",
    "Given an input CNF, we want to parse is so that\n",
    "- Instead of having variables `0`, `1`, `2`..., `n0`, `n1`, `n2`, ... we will work with only integers from now on, therefore we will transform the input CNF into a list of integers such that `x` $\\mapsto$ `x`, and `nx` $\\mapsto$ `x+N` (where `N` is the number of variables)\n",
    "- Ex: `0 1 n2,2 n0 n5,n1 3 4,n3 n4 5` will be parsed to `parsed_cnf = [0,1,8,2,6,11,7,3,4,9,10,5]`\n",
    "- We don't need commas or spaces anymore since we know that the input is a 3SAT CNF, so we know the first clause is represented by `(0,1,8)`, the second one by `(2,6,11)`, etc.\n",
    "\n",
    "The function `parse_cnf()` will ask for two inputs from the user:\n",
    "- The number of variables (here we count $x$ and $\\neg x$ as one variable), so the CNF above has `6` variables.\n",
    "- The CNF (ex: `0 1 n2,2 n0 n5,n1 3 4,n3 n4 5`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cnf_from_str(str_cnf, num_variables):\n",
    "    \"\"\"Parses a CNF from a string given as argument\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    str_cnf: str\n",
    "        the CNF to parse\n",
    "    num_variables: int\n",
    "        the number of variables in the CNF to parse\n",
    "    Returns\n",
    "    -------\n",
    "    list(int)\n",
    "        the parsed CNF according to the conventions we decide to use\n",
    "    \"\"\"\n",
    "    clauses = str_cnf.replace(\",\", \" \")\n",
    "    parsed_cnf = clauses.split(\" \")\n",
    "    for i in range(len(parsed_cnf)):\n",
    "        if parsed_cnf[i].startswith(\"n\"):\n",
    "            parsed_cnf[i] = str(int(parsed_cnf[i][1:])+num_variables)\n",
    "    parsed_cnf = list(map(lambda elem: int(elem), parsed_cnf))\n",
    "    return parsed_cnf, num_variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create a graph from the CNF\n",
    "Let us transform the CNF into a graph $G$, where\n",
    "- Each clause maps to a triangle\n",
    "- The weight of an edge $(i,j)$, $W_{ij}$, is set to $M$ if $j = i+N$, otherwise it is set to the number of triangles that share the edge $(i,j)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph G from an already-parsed CNF\n",
    "def create_maxcut_graph(parsed_cnf, num_variables, penalty_factor, add_nodes=False):\n",
    "    \"\"\"Creates a weighted graph from a CNF\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parsed_cnf : list(int)\n",
    "        the parsed cnf containing values in [0, 2N-1]\n",
    "    num_variables : int\n",
    "        the number of variables used in the CNF (= N)\n",
    "    penalty_factor: int\n",
    "        the penalty factor used for assuring consistency\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nx.Graph\n",
    "        the obtained graph\n",
    "    \"\"\"\n",
    "    \n",
    "    # All the variables used in the parsed cnf (ranging from 0 to 2N-1)\n",
    "    cnf_variables = set(parsed_cnf)\n",
    "\n",
    "    # All the variables used in the original CNF (ranging from 0 to N-1)\n",
    "    variables = set(range(num_variables))\n",
    "\n",
    "    # Will contain the weight associated with each edge (i,j)\n",
    "    edge_weights = {}\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Create the vertices\n",
    "    # vertices = list(cnf_variables) # correct\n",
    "    vertices = range(2*num_variables)\n",
    "    G.add_nodes_from(vertices)\n",
    "    # Iterate over the parsed CNF per clause (3 elements by 3 elements)\n",
    "    for i in range(0, len(parsed_cnf), 3):\n",
    "\n",
    "        # First edge\n",
    "        # If that edge already exists in the map, add 1 to its value\n",
    "        if (parsed_cnf[i], parsed_cnf[i+1]) in edge_weights:\n",
    "            edge_weights[(parsed_cnf[i], parsed_cnf[i+1])] = edge_weights[(parsed_cnf[i], parsed_cnf[i+1])] + 1\n",
    "        else: # Otherwise, set the weight value to 1\n",
    "            edge_weights[(parsed_cnf[i], parsed_cnf[i+1])] = 1\n",
    "\n",
    "        # Second edge\n",
    "        # If that edge already exists in the map, add 1 to its value\n",
    "        if (parsed_cnf[i], parsed_cnf[i+2]) in edge_weights:\n",
    "            edge_weights[(parsed_cnf[i], parsed_cnf[i+2])] = edge_weights[(parsed_cnf[i], parsed_cnf[i+2])] + 1\n",
    "        else: # Otherwise, set the weight value to 1\n",
    "            edge_weights[(parsed_cnf[i], parsed_cnf[i+2])] = 1\n",
    "\n",
    "        # Third edge\n",
    "        # If that edge already exists in the map, add 1 to its value\n",
    "        if (parsed_cnf[i+1], parsed_cnf[i+2]) in edge_weights:\n",
    "            edge_weights[(parsed_cnf[i+1], parsed_cnf[i+2])] = edge_weights[(parsed_cnf[i+1], parsed_cnf[i+2])] + 1\n",
    "        else: # Otherwise, set the weight value to 1\n",
    "            edge_weights[(parsed_cnf[i+1], parsed_cnf[i+2])] = 1\n",
    "    \n",
    "    # Add all the \"clause edges\" to the graph after calculating all the weights needed\n",
    "    for (u,v) in edge_weights.keys():\n",
    "        G.add_edge(u, v, weight=edge_weights[(u,v)], color=\"b\")\n",
    "\n",
    "\n",
    "    # Add all the \"constraint\" edges to the graph, with a weight of penalty_factor each\n",
    "    for var in variables:\n",
    "        # Check if both x and not(x) exist in the CNF (otherwise we don't need to add the penalty term)\n",
    "        if var in cnf_variables and var + num_variables in cnf_variables:\n",
    "            G.add_edge(var, var+num_variables, weight=penalty_factor, color=\"r\")\n",
    "\n",
    "    return G"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Theoretical Cut Value\n",
    "\n",
    "### 3.1) NAE-3SAT Minimization Problem\n",
    "Given a CNF composed of C clauses and with penalty factor M:\n",
    "If the values $\\{w_1, ..., w_{2N}\\}$ satisfy the 3-SAT CNF with the NAE constraint, then (proven):\n",
    "$\\begin{equation}\n",
    "\\min\\limits_{w_i}\\sum\\limits_{j = 1}^{C}(w_1^{(j)}w_2^{(j)} + w_1^{(j)}w_3^{(j)} + w_2^{(j)}w_3^{(j)}) + M\\sum\\limits_{i\\in neg\\_var} w_iw_{i+N} = -C-M\\lvert \\texttt{neg\\_var}\\rvert\n",
    "\\end{equation}$\n",
    "where $w_k^{(j)}$ is variable $k$ in clause $j$, and $\\texttt{neg\\_var}$ is the set of variable indices $i$ such that both $w_i$ and $w_{i+N}$ appear in the parsed CNF. \n",
    "\n",
    "The minimization problem can be transformed into the following:\n",
    "$\\begin{equation}\n",
    "\\min\\limits_{x \\in \\{-1,1\\}^{|V|}} \\left\\{\\sum\\limits_{(i,j) \\in E}W_{ij}x_ix_j\\right\\}\n",
    "\\end{equation}$\n",
    "where $W_{ij}$ is the weight of edge $(i, j)$ from the previously obtained graph (that weight is equal to the number of triangles that share that edge if\n",
    "$j \\neq i + n$, and $M$ otherwise)\n",
    "\n",
    "### 3.2) Link Between NAE-3SAT and Weighted Max-Cut\n",
    "The weighted Max-Cut problem is the following:\n",
    "$\\begin{equation}\n",
    "        \\max\\limits_{x \\in \\{-1,1\\}^{|V|}} \\left\\{\\frac{1}{2}\\sum\\limits_{(i,j) \\in E} W_{ij}(1-x_ix_j)\\right\\} = \\max\\limits_{x \\in \\{-1,1\\}^{|V|}} \\left\\{\\frac{1}{2}\\sum\\limits_{(i,j)\\in E}W_{ij} - \\frac{1}{2}\\sum\\limits_{(i,j) \\in E} W_{ij}x_ix_j\\right\\}\n",
    "\\end{equation}$\n",
    "where $x_k \\in \\{-1, 1\\}$\n",
    "Since we want to maximize this, we would like to minimize the second sum (because of the $-$ sign). However this second sum was computed before and is equal to $-C-M\\lvert\\texttt{neg\\_var}\\rvert$ if $x$ satisfies the CNF with the NAE constraint. \n",
    "\n",
    "Therefore, if $x$ satisfies the CNF with NAE constraint, then the theoretical Max-Cut value is:\n",
    "$\\begin{equation}\n",
    "\\text{MaxCutValue}_{theory} = \\frac{1}{2}\\sum\\limits_{(i,j)\\in E}W_{ij}+\\frac{1}{2}(C+M|neg\\_var|)\n",
    "\\end{equation}$\n",
    "\n",
    "In the next cell we compute this value from the original CNF and the (equivalent) graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the theoretical Max-Cut value according to the previous formula\n",
    "def get_theoretical_maxcut_value(G, parsed_cnf, num_variables, M):\n",
    "    \"\"\"Compute the theoretical max-cut value\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "        the graph whose max-cut to compute\n",
    "    parsed_cnf : list(int)\n",
    "        the parsed cnf containing values in [0, 2N-1]\n",
    "    num_variables: int\n",
    "        the number of variables used in the CNF (= N)\n",
    "    M : int\n",
    "        the penalty factor for consistency\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        the theoretical max-cut value\n",
    "    \"\"\"\n",
    "    # cnf_contribution is the second part of the MaxCutValue_theory above\n",
    "    cut_value = 0\n",
    "    for u,v in G.edges:\n",
    "        cut_value += G[u][v][\"weight\"]/2\n",
    "        \n",
    "    for i in range(num_variables):\n",
    "        if i in parsed_cnf and i + num_variables in parsed_cnf:\n",
    "            cut_value += M/2\n",
    "    cut_value += len(parsed_cnf)/6\n",
    "    return cut_value\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Compute the Max-Cut value Experimentally\n",
    "We can choose to either solve only the relaxed problem (`should_round=False`) or the relaxed + rounding version (`should_round=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.algorithms.optimizers import COBYLA\n",
    "def compute_max_cut_qrao(G, rounding_scheme, intermediate_results, ansatz_reps, should_round=False):\n",
    "    \"\"\"Compute the relaxed max-cut (or rounded max-cut if should_round=True) using the protoype-qrao library\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "        the graph whose max-cut to compute\n",
    "    rounding_scheme: RoundingScheme\n",
    "        the rounding technique to use (ignored when should_round=False)\n",
    "    intermediate_results: list(float)\n",
    "        the intermediate energy values computed from the eigensolver \n",
    "    should_round: bool\n",
    "        if False, we do not perform rounding, otherwise we perform rounding  \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Either a float (non-rounded, relaxed max-cut value) or a list[int] containing the solution to the 3SAT-NAE problem\n",
    "    \"\"\"\n",
    "\n",
    "    maxcut = Maxcut(G)\n",
    "    problem = maxcut.to_quadratic_program()\n",
    "    encoding = QuantumRandomAccessEncoding(3) # Use (3,1)-QRAC\n",
    "    encoding.encode(problem)\n",
    "    ansatz = EfficientSU2(encoding.num_qubits, su2_gates=[\"rx\", \"y\"], reps=ansatz_reps, entanglement=\"linear\")\n",
    "    threads = multiprocessing.cpu_count()\n",
    "\n",
    "    # results will be either a number (if we solve the relaxed version), or \n",
    "    # an array of values in {0,1} (if we perform rounding)\n",
    "    results = None \n",
    "    vqe = VQE(\n",
    "        Estimator(        \n",
    "            approximation=True,\n",
    "            abelian_grouping=False,\n",
    "            backend_options={\"method\": method, \"device\": device, \"max_parallel_experiments\": threads},\n",
    "        ),\n",
    "        ansatz,\n",
    "        COBYLA(maxiter=1000),\n",
    "        # for now let's have this callback\n",
    "        callback= lambda c,p,value,m: intermediate_results.append(problem.objective.sense.value * (encoding.offset + value))\n",
    "    )\n",
    "    # Create the qrao instance\n",
    "    qrao = QuantumRandomAccessOptimizer(encoding=encoding, min_eigen_solver=vqe, rounding_scheme=rounding_scheme)\n",
    "\n",
    "    if not should_round:\n",
    "        # We just need to solve the relaxed problem\n",
    "        eigensolver_result, _ = qrao.solve_relaxed()\n",
    "        # Relaxed MaxCut Value (computed from the gotten minimimum eigenvalue)\n",
    "        results = problem.objective.sense.value * (encoding.offset + eigensolver_result.eigenvalue.real)\n",
    "            \n",
    "\n",
    "    else:\n",
    "        # Otherwise we solve the relaxed problem but also perform rounding at the end\n",
    "        rounded_results = qrao.solve()\n",
    "        results = rounded_results.x # variable assignments\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Calculate the Error (Only Done After Rounding)\n",
    "To calculate the error, we will look at the results (`x_values`) which are the values (0 or 1) we assign to the variables, and check two things:\n",
    "- NAE-SAT errors: If a clause is not NAE-SAT, then we add 1 to the NAE-SAT error\n",
    "- Consistency errors: If a variable is the same as its negation, we add 1 to the consistency error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(parsed_cnf, num_variables, result):\n",
    "    \"\"\"Calculate the NAE-3SAT error\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parsed_cnf: list(int)\n",
    "        the initial parsed CNF\n",
    "    num_variables: int\n",
    "        the number of variables used (without distinguishing x and not x)\n",
    "    result: list(int)\n",
    "        the resulting variable assignments\n",
    "\n",
    "    Returns\n",
    "    int, int\n",
    "        the NAE-SAT error and the consistency error, respectively\n",
    "    \"\"\"\n",
    "    \n",
    "    nae_sat_error = 0\n",
    "    consistency_error = 0\n",
    "    # Iterate over the clauses of the CNF\n",
    "    for i in range(0, len(parsed_cnf), 3):\n",
    "        v1 = result[parsed_cnf[i]]\n",
    "        v2 = result[parsed_cnf[i+1]]\n",
    "        v3 = result[parsed_cnf[i+2]]\n",
    "        # if clause is satisfied but not SAT-NAE, or if the clause is not satisfied, we add 1 to nae_sat_error\n",
    "        if v1 + v2 + v3 == 3 or v1 + v2 + v3 == 0:\n",
    "            nae_sat_error += 1\n",
    "    \n",
    "    for i in range(num_variables):\n",
    "        # if a variable is the same as its negation, we add 1 to consistency_error\n",
    "        if  i + num_variables < len(result) and result[i] == result[i+num_variables]:\n",
    "            consistency_error += 1\n",
    "    return nae_sat_error, consistency_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nonconsistent_cnfs(cnfs):\n",
    "    \"\"\"Filters out the nonconsistent CNFs from a list of CNFs, to make sure QRAO can run them without mapping issues\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cnfs: list(str)\n",
    "        the list of CNFs to filter\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list(str)\n",
    "        the resulting filtered list\n",
    "    \"\"\"\n",
    "    \n",
    "    filtered = []\n",
    "    for i in range(len(cnfs)):\n",
    "        used_variables = set()\n",
    "        num_vars, cnf = cnfs[i].replace(\"\\n\", \"\").split(\" -- \")\n",
    "        num_vars = int(num_vars)\n",
    "        parsed_cnf, num_vars = parse_cnf_from_str(cnf, num_vars)\n",
    "        for j in range(len(parsed_cnf)):\n",
    "            used_variables.add(parsed_cnf[j])\n",
    "        num_vars_ok = True\n",
    "        for j in range(num_vars):\n",
    "            if j not in used_variables or j + num_vars not in used_variables:\n",
    "                num_vars_ok = False\n",
    "        if num_vars_ok:\n",
    "            filtered.append((cnf, num_vars))\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_min_M_value(parsed_cnf):\n",
    "    \"\"\"Calculates the minimal M value required to ensure consistency\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parsed_cnf: list(int)\n",
    "        the input CNF\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        the resulting penalty factor M\n",
    "    \"\"\"\n",
    "    \n",
    "    pair_appearances = {}\n",
    "    for i in range(0, len(parsed_cnf), 3):\n",
    "        v_1 = parsed_cnf[i]\n",
    "        v_2 = parsed_cnf[i+1]\n",
    "        v_3 = parsed_cnf[i+2]\n",
    "    pair_appearances[(v_1,v_2)] = 1 if (v_1, v_2) not in pair_appearances else pair_appearances[(v_1, v_2)] + 1\n",
    "    pair_appearances[(v_1,v_3)] = 1 if (v_1, v_3) not in pair_appearances else pair_appearances[(v_1, v_3)] + 1\n",
    "    pair_appearances[(v_2,v_3)] = 1 if (v_2, v_3) not in pair_appearances else pair_appearances[(v_2, v_3)] + 1\n",
    "    max_appearance = 0\n",
    "    for key in pair_appearances:\n",
    "        if pair_appearances[key] > max_appearance:\n",
    "            max_appearance = pair_appearances[key]\n",
    "    return max_appearance + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_var_clause_success_rate_nae3sat_cnfs(filename):\n",
    "    \"\"\"Reads NAE-3SAT CNFs from a file and runs QRAO on them, and outputs success/failure rates per (num_variables, num_clauses) CNFs\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: str\n",
    "        the name of the file containing NAE-3SAT CNFs\n",
    "    \"\"\"\n",
    "    \n",
    "    num_success = 0\n",
    "    cnfs = None\n",
    "    rounding_scheme = MagicRounding(QuantumInstance(backend=backend, shots=1024))\n",
    "    with open(filename, \"r\") as sat_file:\n",
    "        cnfs = sat_file.readlines()\n",
    "    filtered_cnfs = filter_nonconsistent_cnfs(cnfs)\n",
    "    num_runs = len(filtered_cnfs)\n",
    "    vars_clauses_successes = {}\n",
    "    vars_clauses_runs = {}\n",
    "    current_run_number = 0\n",
    "    for cnf_line in filtered_cnfs:\n",
    "        current_run_number += 1\n",
    "        (cnf, num_vars) = cnf_line\n",
    "        num_vars = int(num_vars)\n",
    "        parsed_cnf, num_vars = parse_cnf_from_str(cnf, num_vars)\n",
    "        percentage = \"%.2f\" % float(100*current_run_number/num_runs) + \"%\"\n",
    "        M = compute_min_M_value(parsed_cnf)     \n",
    "        G = create_maxcut_graph(parsed_cnf, num_vars, M)\n",
    "        intermediate_results = []\n",
    "\n",
    "        x_values = compute_max_cut_qrao(G, rounding_scheme, intermediate_results, int(len(parsed_cnf)/3), should_round=True)\n",
    "        naesat_error, consistency_error = calculate_error(parsed_cnf, num_vars, x_values)\n",
    "        num_clauses = cnf.count(\",\") + 1\n",
    "        if naesat_error + consistency_error == 0:\n",
    "            if (num_vars, num_clauses) not in vars_clauses_successes:\n",
    "                vars_clauses_successes[(num_vars, num_clauses)] = 1\n",
    "            else:\n",
    "                vars_clauses_successes[(num_vars, num_clauses)] += 1\n",
    "            num_success += 1\n",
    "        else:\n",
    "            if (num_vars, num_clauses) not in vars_clauses_successes:\n",
    "                    vars_clauses_successes[(num_vars, num_clauses)] = 0\n",
    "        \n",
    "        if (num_vars, num_clauses) not in vars_clauses_runs:\n",
    "            vars_clauses_runs[(num_vars, num_clauses)] = 1\n",
    "        else:\n",
    "            vars_clauses_runs[(num_vars, num_clauses)] += 1\n",
    "        success_rate = \"%.2f\" % float(100*num_success/current_run_number) + \"%\"\n",
    "        print(f\"Run {current_run_number}/{num_runs} | {percentage} | success_rate = {success_rate}\", end=\"\\r\")\n",
    "\n",
    "    total_success_rate = \"%.2f\" % float(100*num_success/num_runs) + \"%\" \n",
    "    print(f\"Total Success Rate: {num_success}/{num_runs} ({total_success_rate})\")\n",
    "    for (num_vars, num_clauses) in vars_clauses_runs:\n",
    "        v_c_success_rate = \"%.2f\" % float(100*vars_clauses_successes[(num_vars, num_clauses)]/vars_clauses_runs[(num_vars, num_clauses)]) + \"%\"\n",
    "        num_v_c_successes = vars_clauses_successes[(num_vars, num_clauses)]\n",
    "        num_v_c_runs = vars_clauses_runs[(num_vars, num_clauses)]\n",
    "        print(f\"For {num_vars} variables on {num_clauses} clauses: Success Rate = {v_c_success_rate} ({num_v_c_successes}/{num_v_c_runs})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on NAE-3SAT CNFs\n",
    "compute_var_clause_success_rate_nae3sat_cnfs(\"nae3sat_cnfs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result_for_nae3sat_cnfs(nae_filename, runs_per_cnf):\n",
    "    \"\"\"Reads NAE-3SAT CNFs from a file one by one, runs QRAO on them, then calculates and outputs the success rate per CNF.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nae_filename: str\n",
    "        the file to read the NAE-3SAT CNFs from\n",
    "    runs_per_cnf: int\n",
    "        the number of runs per CNF\n",
    "    \"\"\"\n",
    "\n",
    "    rounding_scheme = MagicRounding(quantum_instance=QuantumInstance(backend=backend, shots=2000))\n",
    "    intermediate_results = []\n",
    "    nae_file = open(nae_filename, \"r\")\n",
    "    nae_cnfs = list(map(lambda elem: elem.replace(\"\\n\", \"\"), nae_file.readlines()))\n",
    "    nae_file.close()\n",
    "    num_nae_cnfs = len(nae_cnfs)\n",
    "\n",
    "    for cnf_index in range(len(nae_cnfs)):\n",
    "        [num_vars_str, cnf] = nae_cnfs[cnf_index].split(\" -- \")\n",
    "        num_vars = int(num_vars_str)\n",
    "        if num_vars >= 9:\n",
    "            parsed_cnf, _ = parse_cnf_from_str(cnf, num_vars)\n",
    "            num_clauses = int(len(parsed_cnf)/3)\n",
    "            M = compute_min_M_value(parsed_cnf)\n",
    "            print(f\"M = {M}\")\n",
    "            G = create_maxcut_graph(parsed_cnf, num_vars, M)\n",
    "            individual_success_rate = 0\n",
    "            for i in range(runs_per_cnf):\n",
    "                x_values = compute_max_cut_qrao(G, rounding_scheme, intermediate_results, ansatz_reps=max(num_clauses, 10), should_round=True)\n",
    "                satnae_error, consistency_error = calculate_error(parsed_cnf, num_vars, x_values)\n",
    "                if satnae_error + consistency_error == 0:\n",
    "                    individual_success_rate += 1\n",
    "\n",
    "            print(f\"Success Rate For ({num_vars}, {num_clauses}): {100*individual_success_rate/runs_per_cnf}\")\n",
    "            print(f\"Progress: {cnf_index+1}/{num_nae_cnfs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on NAE-3SAT CNFs with 10 runs per instance\n",
    "predict_result_for_nae3sat_cnfs(\"nae3sat_cnfs.txt\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(nae3sat_filename, nonnae3sat_filename):\n",
    "    \"\"\"Classifies CNFs into NAE-3SAT or non-NAE-3SAT based on the relaxed energy value, and outputs the confusion matrix\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nae3sat_filename: str\n",
    "        the name of the file containing NAE-3SAT CNFs\n",
    "    nonnae3sat_filename: str\n",
    "        the name of the file containing non-NAE-3SAT CNFs\n",
    "    \"\"\"\n",
    "    \n",
    "    rounding_scheme = MagicRounding(quantum_instance=QuantumInstance(backend=backend, shots=2000))\n",
    "    intermediate_results = []\n",
    "    nae_file = open(nae3sat_filename, \"r\")\n",
    "    nae_cnfs = list(map(lambda elem: elem.replace(\"\\n\", \"\"), nae_file.readlines()))\n",
    "    nae_file.close()\n",
    "    num_nae_cnfs = len(nae_cnfs)\n",
    "    nonnae_file = open(nonnae3sat_filename, \"r\")\n",
    "    nonnae_cnfs = list(map(lambda elem: elem.replace(\"\\n\", \"\"), nonnae_file.readlines()))\n",
    "    nonnae_file.close()\n",
    "    num_nonnae_cnfs  = len(nonnae_cnfs)\n",
    "    sat_but_predicted_unsat = 0\n",
    "    sat_and_predicted_sat = 0\n",
    "    unsat_but_predicted_sat = 0\n",
    "    unsat_and_predicted_unsat = 0\n",
    "    for cnf_index in range(len(nae_cnfs)):\n",
    "        [num_vars_str, cnf] = nae_cnfs[cnf_index].split(\" -- \")\n",
    "        num_vars = int(num_vars_str)\n",
    "        parsed_cnf, _ = parse_cnf_from_str(cnf, num_vars)\n",
    "        num_clauses = int(len(parsed_cnf)/3)\n",
    "        M = compute_min_M_value(parsed_cnf)\n",
    "        G = create_maxcut_graph(parsed_cnf, num_vars, M)\n",
    "        theoretical_maxcut_value = get_theoretical_maxcut_value(G, parsed_cnf, num_vars, M)\n",
    "        inclination = 0\n",
    "        for _ in range(1):\n",
    "            relaxed_maxcut_value = compute_max_cut_qrao(G, rounding_scheme, intermediate_results, ansatz_reps=num_vars + num_clauses, should_round=False)\n",
    "            if theoretical_maxcut_value <= relaxed_maxcut_value:\n",
    "                inclination += 1\n",
    "            else:\n",
    "                inclination -= 1\n",
    "        sat_and_predicted_sat = sat_and_predicted_sat + 1 if inclination > 0 else sat_and_predicted_sat\n",
    "        sat_but_predicted_unsat = sat_but_predicted_unsat + 1 if inclination < 0 else sat_but_predicted_unsat\n",
    "        progress_percentage = \"%.2f\" % float(100*(cnf_index+1)/num_nae_cnfs) + \"%\"\n",
    "        print(f\"Progress (SAT): {progress_percentage}\", end=\"\\r\")\n",
    "    print()\n",
    "    print(\"--- STARTING UNSAT ---\")\n",
    "    for cnf_index in range(len(nonnae_cnfs)):\n",
    "        [num_vars_str, cnf] = nonnae_cnfs[cnf_index].split(\" -- \")\n",
    "        num_vars = int(num_vars_str)\n",
    "        parsed_cnf, _ = parse_cnf_from_str(cnf, num_vars)\n",
    "        num_clauses = int(len(parsed_cnf)/3)\n",
    "        M = compute_min_M_value(parsed_cnf)\n",
    "        G = create_maxcut_graph(parsed_cnf, num_vars, M)\n",
    "        inclination = 0\n",
    "        for _ in range(1):\n",
    "            theoretical_maxcut_value = get_theoretical_maxcut_value(G, parsed_cnf, num_vars, M)\n",
    "            relaxed_maxcut_value = compute_max_cut_qrao(G, rounding_scheme, intermediate_results, ansatz_reps=num_vars + num_clauses, should_round=False)\n",
    "            if theoretical_maxcut_value > relaxed_maxcut_value:\n",
    "                inclination += 1\n",
    "            else:\n",
    "                inclination -= 1\n",
    "        unsat_and_predicted_unsat = unsat_and_predicted_unsat + 1 if inclination > 0 else unsat_and_predicted_unsat\n",
    "        unsat_but_predicted_sat = unsat_but_predicted_sat + 1 if inclination < 0 else unsat_but_predicted_sat\n",
    "        progress_percentage = \"%.2f\" % float(100*(cnf_index+1)/num_nonnae_cnfs) + \"%\"\n",
    "        print(f\"Progress (SAT): {progress_percentage}\", end=\"\\r\")\n",
    "    print()\n",
    "    print()\n",
    "    print(f\"For {num_nae_cnfs} CNFs: predicted {sat_and_predicted_sat} as SAT and {sat_but_predicted_unsat} as UNSAT\")\n",
    "    print(f\"For {num_nonnae_cnfs} CNFs: predicted {unsat_and_predicted_unsat} as UNSAT and {unsat_but_predicted_sat} as SAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify NAE-3SAT and non-NAE-3SAT CNFs\n",
    "classify(\"nae3sat_cnfs_nonreduced.txt\", \"non-nae3sat_cnfs_nonreduced.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
